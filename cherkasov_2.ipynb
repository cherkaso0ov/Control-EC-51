{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загружаем наш дата сет. Мы имеем дата сет из 10 колонок (Age, Sex, ALP, ALT, AST, BIL, CHE, CHOL, CREA, Category) и 615 строк. Есть как числовые, так и качественные переменные. Крайний столбец Category выступает как классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем необходимые библиотеки для начала работы (Numpy, Matplotlib.pyplot ,Pandas)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем дата сет в формате сsv, разделитель запятые.\n",
    "df = pd.read_csv('cont.csv', sep=',' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>BIL</th>\n",
       "      <th>CHE</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>CREA</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>52.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.93</td>\n",
       "      <td>3.23</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>70.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>11.17</td>\n",
       "      <td>4.80</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>74.7</td>\n",
       "      <td>36.2</td>\n",
       "      <td>52.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>5.20</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>18.9</td>\n",
       "      <td>7.33</td>\n",
       "      <td>4.74</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>m</td>\n",
       "      <td>74.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.15</td>\n",
       "      <td>4.32</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>62</td>\n",
       "      <td>f</td>\n",
       "      <td>416.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>110.3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.57</td>\n",
       "      <td>6.30</td>\n",
       "      <td>55.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>64</td>\n",
       "      <td>f</td>\n",
       "      <td>102.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>44.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>3.02</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>64</td>\n",
       "      <td>f</td>\n",
       "      <td>87.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.63</td>\n",
       "      <td>66.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>46</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>4.20</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>59</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.07</td>\n",
       "      <td>5.30</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Sex    ALP    ALT    AST   BIL    CHE  CHOL   CREA  Category\n",
       "0     32   m   52.5    7.7   22.1   7.5   6.93  3.23  106.0         0\n",
       "1     32   m   70.3   18.0   24.7   3.9  11.17  4.80   74.0         0\n",
       "2     32   m   74.7   36.2   52.6   6.1   8.84  5.20   86.0         0\n",
       "3     32   m   52.0   30.6   22.6  18.9   7.33  4.74   80.0         0\n",
       "4     32   m   74.1   32.6   24.8   9.6   9.15  4.32   76.0         0\n",
       "..   ...  ..    ...    ...    ...   ...    ...   ...    ...       ...\n",
       "610   62   f  416.6    5.9  110.3  50.0   5.57  6.30   55.7         1\n",
       "611   64   f  102.8    2.9   44.4  20.0   1.54  3.02   63.0         1\n",
       "612   64   f   87.3    3.5   99.0  48.0   1.66  3.63   66.7         1\n",
       "613   46   f    NaN   39.0   62.0  20.0   3.56  4.20   52.0         1\n",
       "614   59   f    NaN  100.0   80.0  12.0   9.07  5.30   67.0         1\n",
       "\n",
       "[615 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверяем как загрузился дата сет. Сразу видно присутствие NaN в столбцах\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем и заменяем пропуски в числовых столбцах дата сета.\n",
    "def fill_missing_num(x):\n",
    "    num_var = list(x._get_numeric_data().columns)\n",
    "    for col_names in num_var:        \n",
    "        prep_med = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "        prep_med.fit(x[num_var])\n",
    "        x[num_var] = prep_med.transform(x[num_var])\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем значения NaN с помощью SimpleImputer.\n",
    "from sklearn.impute import SimpleImputer\n",
    "df = fill_missing_num(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Производим кодирование всех качественных переменных, в нашем случае только столбец Sex.\n",
    "def encoding_char(x):\n",
    "    char_var = list(set(x.columns) - set(x._get_numeric_data().columns))\n",
    "    for col_names in char_var:\n",
    "        f = pd.factorize(x[col_names])\n",
    "        x[col_names] = pd.factorize(x[col_names])[0]\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encoding_char(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делим наш дата сет на обучающую и тестирующую выборку в пропорции 20/80.\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Производим шкалирование наших данных без нашей эдогенной переменной Category.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler().fit(X_train)\n",
    "X_train = sc_X.transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.312738\n",
      "         Iterations 8\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.214     \n",
      "Dependent Variable: y                AIC:              325.7338  \n",
      "Date:               2020-11-23 12:00 BIC:              363.5201  \n",
      "No. Observations:   492              Log-Likelihood:   -153.87   \n",
      "Df Model:           8                LL-Null:          -195.80   \n",
      "Df Residuals:       483              LLR p-value:      8.1273e-15\n",
      "Converged:          1.0000           Scale:            1.0000    \n",
      "No. Iterations:     8.0000                                       \n",
      "--------------------------------------------------------------------\n",
      "       Coef.     Std.Err.       z       P>|z|      [0.025     0.975]\n",
      "--------------------------------------------------------------------\n",
      "x1     0.0023      0.1505     0.0155    0.9877    -0.2927     0.2973\n",
      "x2     0.1901      0.1652     1.1504    0.2500    -0.1338     0.5139\n",
      "x3    -0.0718      0.2285    -0.3145    0.7532    -0.5196     0.3760\n",
      "x4    -1.4307      0.2335    -6.1277    0.0000    -1.8883    -0.9731\n",
      "x5     7.3728      0.6351    11.6094    0.0000     6.1281     8.6175\n",
      "x6     1.1551      0.3660     3.1556    0.0016     0.4376     1.8725\n",
      "x7    -0.2509      0.1840    -1.3632    0.1728    -0.6115     0.1098\n",
      "x8    -0.1494      0.1762    -0.8479    0.3965    -0.4947     0.1959\n",
      "x9     0.0912      0.1883     0.4845    0.6281    -0.2779     0.4604\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Строим базовую модель и смотрим на полученный отчет. Можно сделать вывод, что значимых перменных только две, это х4 (ALT) и х5 (AST). Будем использовать их для построения наших классификаторов.\n",
    "import statsmodels.api as sm\n",
    "lr = sm.Logit(y_train, X_train).fit()\n",
    "print(lr.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Остлавляем только значимые переменные.\n",
    "X_train = X_train[:,[3,4]]\n",
    "X_test = X_test[:,[3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель логистической регрессии.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state = 13).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.959349593495935"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Делаем прогноз на тестовой выборке. Уровень качества модели очень высок, превышает 95%, то  есть 95% объектов распознано верно.\n",
    "y_pred = lr.predict(X_test)\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108   0]\n",
      " [  5  10]]\n"
     ]
    }
   ],
   "source": [
    "# Строим таблицу сопряженности. Можно сделать вывод, что 5 положительных случая ложно определены как отрицательные. \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Строим область значений. Они отделяются линейно. Зелёные точки - больные люди, красные точки - здоровые. Люди с повышенным значением AST более склонны к болезни. \n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, lr.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Logistic Regression (Test set)')\n",
    "plt.xlabel('ALT')\n",
    "plt.ylabel('AST')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем необходимые пакеты Keras.\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим нейронную сеть прямой передачи сигнала. На входном слое 8 нейрона (усложнее). Используем функцию relu, которая позволит учесть наличие линейнносоти в исходных данных. На втором слое выбирем 1 нейрон используя сигмоидальную функцию. \n",
    "cnn = Sequential()\n",
    "cnn.add(Dense(units = 8,  activation = 'relu', input_dim = 2))\n",
    "cnn.add(Dense(units = 1,  activation = 'sigmoid'))\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 502us/step - loss: 0.7031 - accuracy: 0.3476\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.6257 - accuracy: 0.8923\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 482us/step - loss: 0.5684 - accuracy: 0.9126\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.5181 - accuracy: 0.9289\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 483us/step - loss: 0.4728 - accuracy: 0.9309\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.4307 - accuracy: 0.9370\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.3925 - accuracy: 0.9370\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 448us/step - loss: 0.3586 - accuracy: 0.9390\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.3293 - accuracy: 0.9390\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 499us/step - loss: 0.3042 - accuracy: 0.9370\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 483us/step - loss: 0.2830 - accuracy: 0.9390\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.2655 - accuracy: 0.9390\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.2510 - accuracy: 0.9390\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 483us/step - loss: 0.2388 - accuracy: 0.9390\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.2294 - accuracy: 0.9390\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 464us/step - loss: 0.2210 - accuracy: 0.9390\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.2145 - accuracy: 0.9390\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.2084 - accuracy: 0.9390\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.2034 - accuracy: 0.9390\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 459us/step - loss: 0.1996 - accuracy: 0.9390\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 453us/step - loss: 0.1957 - accuracy: 0.9390\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 452us/step - loss: 0.1928 - accuracy: 0.9390\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 530us/step - loss: 0.1897 - accuracy: 0.9390\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1873 - accuracy: 0.9390\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.1848 - accuracy: 0.9390\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.1830 - accuracy: 0.9390\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 484us/step - loss: 0.1806 - accuracy: 0.9390\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 499us/step - loss: 0.1787 - accuracy: 0.9390\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1768 - accuracy: 0.9390\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 461us/step - loss: 0.1751 - accuracy: 0.9390\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.1735 - accuracy: 0.9370\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1718 - accuracy: 0.9370\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.1703 - accuracy: 0.9370\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 467us/step - loss: 0.1691 - accuracy: 0.9370\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.1677 - accuracy: 0.9370\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 479us/step - loss: 0.1666 - accuracy: 0.9370\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1651 - accuracy: 0.9390\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1640 - accuracy: 0.9390\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.1629 - accuracy: 0.9411\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 463us/step - loss: 0.1618 - accuracy: 0.9431\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.1606 - accuracy: 0.9431\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.1598 - accuracy: 0.9431\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 494us/step - loss: 0.1588 - accuracy: 0.9451\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 461us/step - loss: 0.1580 - accuracy: 0.9431\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.1571 - accuracy: 0.9431\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 461us/step - loss: 0.1564 - accuracy: 0.9451\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.1553 - accuracy: 0.9472\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 451us/step - loss: 0.1547 - accuracy: 0.9451\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.1537 - accuracy: 0.9472\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.1531 - accuracy: 0.9472\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.1526 - accuracy: 0.9472\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1518 - accuracy: 0.9472\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1511 - accuracy: 0.9451\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.1504 - accuracy: 0.9472\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 458us/step - loss: 0.1497 - accuracy: 0.9472\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.1493 - accuracy: 0.9472\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 444us/step - loss: 0.1485 - accuracy: 0.9472\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 418us/step - loss: 0.1482 - accuracy: 0.9472\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1474 - accuracy: 0.9472\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.1469 - accuracy: 0.9472\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.1461 - accuracy: 0.9472\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 457us/step - loss: 0.1457 - accuracy: 0.9472\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 469us/step - loss: 0.1452 - accuracy: 0.9472\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1445 - accuracy: 0.9472\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 467us/step - loss: 0.1439 - accuracy: 0.9472\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 464us/step - loss: 0.1434 - accuracy: 0.9492\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1428 - accuracy: 0.9492\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 475us/step - loss: 0.1424 - accuracy: 0.9492\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1418 - accuracy: 0.9492\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1413 - accuracy: 0.9492\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 483us/step - loss: 0.1408 - accuracy: 0.9472\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1402 - accuracy: 0.9492\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1400 - accuracy: 0.9492\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 442us/step - loss: 0.1394 - accuracy: 0.9492\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1393 - accuracy: 0.9492\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 478us/step - loss: 0.1388 - accuracy: 0.9492\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.1384 - accuracy: 0.9492\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.1379 - accuracy: 0.9492\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.1374 - accuracy: 0.9492\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.1371 - accuracy: 0.9492\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 434us/step - loss: 0.1368 - accuracy: 0.9492\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1366 - accuracy: 0.9472\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.1360 - accuracy: 0.9472\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 483us/step - loss: 0.1358 - accuracy: 0.9472\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.1355 - accuracy: 0.9492\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 457us/step - loss: 0.1353 - accuracy: 0.9512\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 433us/step - loss: 0.1352 - accuracy: 0.9492\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.1346 - accuracy: 0.9492\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 437us/step - loss: 0.1345 - accuracy: 0.9492\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1341 - accuracy: 0.9492\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.1340 - accuracy: 0.9492\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1338 - accuracy: 0.9492\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 496us/step - loss: 0.1335 - accuracy: 0.9492\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 451us/step - loss: 0.1332 - accuracy: 0.9492\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 462us/step - loss: 0.1328 - accuracy: 0.9533\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 462us/step - loss: 0.1327 - accuracy: 0.9533\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1324 - accuracy: 0.9492\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.1322 - accuracy: 0.9533\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 441us/step - loss: 0.1320 - accuracy: 0.9533\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 515us/step - loss: 0.1322 - accuracy: 0.9512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x211f5047970>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучаем нейронную сеть в течении 100 эпох.\n",
    "cnn.fit(X_train, y_train, epochs = 100, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим прогноз на тестовой выборке.\n",
    "y_pred = cnn.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108   0]\n",
      " [  3  12]]\n"
     ]
    }
   ],
   "source": [
    "# Строим таблицу сопряженности. Можно сделать вывод, что 3 положительных случая ложно определены как отрицательные.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Строим область значений. Они отделяются уже не линейно. Однако после усложения модели после увеличения входных нейронов с 2 до 8, качество модели улучшилось. \n",
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, cnn.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('NN (Test set)')\n",
    "plt.xlabel('ALT')\n",
    "plt.ylabel('AST')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выводы. Подводя итоги можно сказать, что исходная логистическая модель обладает повышенной качественностью и определяет 95% объектов верно. Так же стоит отметить, что позитивные и негативные значения отдлеяются линейно. Эту линейность мы используем для построения нейронной сети. При использовании стандартных параметров мы получаем качество модели худше, но при этом сохраняется линейность отделения позитивных от негативных. Для улучшения качества модели было принято решение увеличить количество нейронов на первом слое с 2 до 8, что позволило немного улучшить качество модели в целом, однако разделение положительных от отрицательных более не линейно. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
